{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNICEF India is committed in its continued support to the Government in this extraordinary journey of development to reach every child everywhere in India. Our goal is to enable every child born in India to have the best start in life, to thrive and to develop to her or his full potential.\n"
     ]
    }
   ],
   "source": [
    "# import module\n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "# Taking the NGO name as an input from the user\n",
    "NGO = \"unicef\"\n",
    "\n",
    "# Generating the url\n",
    "url = \"https://google.com/search?q=about us+in+\" + NGO\n",
    "\n",
    "# Sending HTTP request\n",
    "request_result = requests.get( url )\n",
    "\n",
    "# Pulling HTTP data from internet\n",
    "soup = bs4.BeautifulSoup( request_result.text\n",
    "\t\t\t\t\t\t, \"html.parser\" )\n",
    "\n",
    "# Finding Information about the NGO\n",
    "# The INFO is stored inside the class \"BNeawe\".\n",
    "INFO= soup.find( \"div\" , class_='BNeawe' ).text\n",
    "\t\n",
    "print( INFO )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "r = requests.get('https://api.scrapingdog.com/linkedin/?api_key=6109023287f42059e63cdd78&type=company&linkId=google/about/').text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(r,'html.parser')\n",
    "l={}\n",
    "u=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   l['Company']=soup.find('h1',{'class':'org-top-card-summary__title t-24 t-black truncate'}).text.replace('\\n')\n",
    "except:\n",
    "   l['Company']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "allProp = soup.find_all('dd',{'class':'org-page-details__definition-text t-14 t-black — light t-normal'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    " l['website']=allProp[0].text.replace('\\n')\n",
    "except:\n",
    " l['website']=None\n",
    "try:\n",
    " l['Industry']=allProp[1].text.replace('\\n')\n",
    "except:\n",
    " l['Industry']=None\n",
    "try:\n",
    " l['Address']=allProp[2].text.replace('\\n')\n",
    "except:\n",
    " l['Address']=None\n",
    "try:\n",
    " l['Type']=allProp[3].text.replace('\\n')\n",
    "except:\n",
    " l['Type']=None\n",
    "try:\n",
    " l['Specialties']=allProp[4].text.replace('\\n')\n",
    "except:\n",
    " l['Specialties']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    " l['Company Size']=soup.find('dd',{'class':'org-about-company-module__company-size-definition-text t-14 t-black — light mb1 fl'}).text.replace('\\n')\n",
    "except:\n",
    " l['Company Size']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.append(l)\n",
    "df = pd.json_normalize(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('linkedin.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Company website Industry Address  Type Specialties Company Size\n",
      "0    None    None     None    None  None        None         None\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr Shirish S Garud | TERI\n"
     ]
    }
   ],
   "source": [
    "# import module\n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "# Taking the linkdein name as an input from the user\n",
    "Person = \"shirish garud\"\n",
    "\n",
    "# Generating the url\n",
    "url = \"https://google.com/search?q=about us+in+\" + Person\n",
    "\n",
    "# Sending HTTP request\n",
    "request_result = requests.get( url )\n",
    "\n",
    "# Pulling HTTP data from internet\n",
    "soup = bs4.BeautifulSoup( request_result.text\n",
    "\t\t\t\t\t\t, \"html.parser\" )\n",
    "\n",
    "# Finding Information about the profile\n",
    "# The profile is stored inside the class \"BNeawe\".\n",
    "profile= soup.find( \"div\" , class_='BNeawe' ).text\n",
    "\t\n",
    "print( profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
